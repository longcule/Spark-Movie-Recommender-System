{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>\n",
    "    \n",
    "<p>\n",
    "<center>\n",
    "<font size=\"5\">\n",
    "Collaborative Filtering \n",
    "</font>\n",
    "</center>\n",
    "    <center>\n",
    "<font size=\"4\">\n",
    "Model-Based Collaborative Filtering Using ALS\n",
    "</font>\n",
    "</center>\n",
    "</p>\n",
    "   \n",
    "</b>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><h2>Table of Contents<span class=\"tocSkip\"></span></h2></p>\n",
    "\n",
    "<div class=\"toc\"><ul class=\"toc-item\">\n",
    "<li><span><a href=\"#Import\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Overview</a></span></li>\n",
    "    <li><span><a href=\"#Import\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Import Library</a></span></li>\n",
    "    <li><span><a href=\"#LoadData\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Load Data</a></span>\n",
    "        <li><span><a href=\"#BestModel\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Find Best Model</a></span>\n",
    "        <ul class=\"toc-item\">\n",
    "            <li><span><a ><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Split Data</a></span></li>\n",
    "            <li><span><a ><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Build Model</a></span></li>\n",
    "            <li><span><a ><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>ParamGrid Builder and choose Best Model</a></span></li>\n",
    "            <li><span><a ><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Save&Load Model</a></span></li></ul></li>\n",
    "    <li><span><a ><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Build Recommend For User(20 movies)</a></span></li>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aim\n",
    "1.  Sử dụng thuật toán Alternating Least Squares(ALS) để dự đoán rating của người dùng với tất cả các bộ phim \n",
    "2. Đưa ra top 20 bộ phim có dự đoán rating cao nhất của từng người dùng"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"SPARK_HOME\"] = \"/opt/spark\"\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64/jre\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.ml.recommendation import ALSModel\n",
    "from pyspark.sql import SparkSession,SQLContext\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.functions import explode\n",
    "from pyspark.sql.functions import mean, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/27 11:33:18 WARN Utils: Your hostname, longcule-Inspiron-7591 resolves to a loopback address: 127.0.1.1; using 192.168.1.40 instead (on interface enx68e43b306c5a)\n",
      "23/05/27 11:33:18 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/05/27 11:33:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Project\") \\\n",
    "    .master(\"spark://127.0.0.1:7077\") \\\n",
    "    .config(\"spark.driver.memory\", \"16g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.cores\", \"8\") \\\n",
    "    .config(\"spark.driver.extraJavaOptions\", \"-Xss512m\") \\\n",
    "    .config(\"spark.executor.extraJavaOptions\", \"-Xss512m\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "ratings_df = spark.read.csv(\"hdfs://127.0.0.1:9900/user/ratings.csv\", header=True, inferSchema=True)\n",
    "movies = spark.read.csv(\"hdfs://127.0.0.1:9900/user/movies.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating| timestamp|\n",
      "+------+-------+------+----------+\n",
      "|     1|    307|   3.5|1256677221|\n",
      "|     1|    481|   3.5|1256677456|\n",
      "|     1|   1091|   1.5|1256677471|\n",
      "|     1|   1257|   4.5|1256677460|\n",
      "|     1|   1449|   4.5|1256677264|\n",
      "+------+-------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[userId: int, movieId: int, rating: double]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.show(5)\n",
    "ratings_df.drop('timestamp')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprase data rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:==========================================================(8 + 0) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 0.9981816370521007)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "numerator = ratings_df.count()\n",
    "\n",
    "users = ratings_df.select(\"userId\").distinct().count()\n",
    "movies = ratings_df.select(\"movieId\").distinct().count()\n",
    "\n",
    "denominator = users * movies\n",
    "\n",
    "sparsity = 1 - (numerator*1.0 / denominator)\n",
    "print (\"Sparsity: \"), sparsity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Best Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data (Train/test - 80/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_data, test_data) = ratings_df.randomSplit([0.8, 0.2], seed = 3834)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_ALS(train_data, validation_data, num_iters, reg_params, ranks):\n",
    "    min_error = float('inf')\n",
    "    best_rank = -1\n",
    "    best_regularization = 0\n",
    "    best_model = None\n",
    "    \n",
    "    for num_iter in num_iters: \n",
    "        for rank in ranks:\n",
    "            for reg_param in reg_params:\n",
    "                als = ALS(rank=rank, maxIter=num_iter, regParam=reg_param, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\", coldStartStrategy=\"drop\")\n",
    "                model = als.fit(train_data)\n",
    "\n",
    "                predictions = model.transform(validation_data)\n",
    "                evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "                rmse_error = evaluator.evaluate(predictions)\n",
    "                print(\"Root-mean-square error = \" + str(rmse_error))\n",
    "\n",
    "                print('rank: {}, num_iter: {}, reg_param: {} validation RMSE is {}'.format(rank, num_iter, reg_param, rmse_error))\n",
    "                if rmse_error < min_error:\n",
    "                    min_error = rmse_error\n",
    "                    best_rank = rank\n",
    "                    best_regularization = reg_param\n",
    "                    best_model = model\n",
    "    \n",
    "    print('The best model has {} latent factors and regularization = {}'.format(best_rank, best_regularization))\n",
    "    return best_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ParamGridBuilder Choose Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 553:=====================================================> (32 + 1) / 33]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 0.7784632834708709\n",
      "rank: 100, num_iter: 50, reg_param: 0.05 validation RMSE is 0.7784632834708709\n",
      "The best model has 100 latent factors and regularization = 0.05\n",
      "Total Runtime: 4457.57 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "num_iterations = [50]\n",
    "ranks = [100]\n",
    "reg_params = [0.05]\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "final_model = train_ALS(training_data, test_data, num_iterations, reg_params, ranks)\n",
    "\n",
    "print ('Total Runtime: {:.2f} seconds'.format(time.time() - start_time))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save & Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "final_model.save(\"ALS_Movielens_27M\")\n",
    "final_model = ALSModel.load(\"ALS_Movielens_27M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/spark/python/pyspark/sql/context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n",
      "[Stage 766:=====================================================>(99 + 1) / 100]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|userId|     recommendations|\n",
      "+------+--------------------+\n",
      "|    26|[{86955, 5.729708...|\n",
      "|    27|[{134853, 4.86921...|\n",
      "|    28|[{156846, 5.15952...|\n",
      "|    31|[{142871, 5.21941...|\n",
      "|    34|[{188189, 4.75715...|\n",
      "|    44|[{8533, 4.837329}...|\n",
      "|    53|[{108180, 4.57013...|\n",
      "|    65|[{131166, 4.78489...|\n",
      "|    76|[{123497, 4.96401...|\n",
      "|    78|[{2571, 4.879174}...|\n",
      "|    81|[{60983, 5.271923...|\n",
      "|    85|[{2502, 3.9420466...|\n",
      "|   101|[{144448, 4.66748...|\n",
      "|   108|[{86237, 5.278370...|\n",
      "|   115|[{2609, 4.8907127...|\n",
      "|   126|[{171011, 4.38200...|\n",
      "|   133|[{2795, 4.0398917...|\n",
      "|   137|[{92136, 4.767501...|\n",
      "|   148|[{93040, 4.541998...|\n",
      "|   155|[{103751, 5.50779...|\n",
      "+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "userRecs = final_model.recommendForAllUsers(20)\n",
    "\n",
    "userRecs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "userRecs.write.mode('overwrite').parquet('model')\n",
    "recommendation = spark.read.parquet('model')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Recommend For User (20 movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1197,\n",
       " 120807,\n",
       " 105189,\n",
       " 61013,\n",
       " 160289,\n",
       " 7361,\n",
       " 134849,\n",
       " 90464,\n",
       " 183947,\n",
       " 159817,\n",
       " 2502,\n",
       " 1449,\n",
       " 1288,\n",
       " 176601,\n",
       " 6375,\n",
       " 3911,\n",
       " 101850,\n",
       " 7141,\n",
       " 175879,\n",
       " 171011]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_recommendations(user_id):\n",
    "    recs = recommendation.filter(col(\"userId\") == user_id).select(\"recommendations\")\n",
    "    recs = recs.select(explode(col(\"recommendations\")).alias(\"rec\")).select(\"rec.movieId\", \"rec.rating\")\n",
    "    item_list = recs.orderBy(col(\"rating\").desc()).select(\"movieId\").rdd.flatMap(lambda x: x).collect()\n",
    "    return item_list\n",
    "\n",
    "get_recommendations(1) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
